This is a collection of [Kaggle](https://kaggle.com) competitions with which I have trained and learnt various aspects of data science and machine learning methods. So far, the projects are:

1. Disaster Titanic: predict the survival of passengers of Titanic using various features (class, cabin position, gender, etc...). I mostly followed a thorough guide on this one to discover the subtle details of filling missing values and feature engineering.
2. Spaceship Titanic: a more thorough version of the previous one, with many missing values. I used what I learnt from Disaster Titanic to do this (I used inspiration from various posts for the very difficult last missing values). This only contains a very simple training by a Random Forest Classifier (no model selection or cross validation yet) as this led to a very satisfactory result of nearly 80% success. This confirmed to me that missing values and feature engineering is indeed a crucial aspect of training a good machine learning model.