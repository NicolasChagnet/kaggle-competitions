This is a collection of [Kaggle](https://kaggle.com) competitions with which I have trained and learnt various aspects of data science and machine learning methods. So far, the projects are:

1. Disaster Titanic: predict the survival of passengers of Titanic using various features (class, cabin position, gender, etc...). I mostly followed a thorough guide on this one to discover the subtle details of filling missing values and feature engineering.
2. Spaceship Titanic: a more thorough version of the previous one, with lots of missing values. I used what I learnt from Titanic Disaster to do it by myself (I used inspiration from various posts for the very difficult last missing values). Only contains a very simple training by a Random Forest Classifier (no model selection or cross validation yet) as this led to a very satisfactory result of nearly 80% success. This confirmed to me that missing values and feature engineering is indeed a crucial aspect of training a good machine learning model.